{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fc2ae5",
   "metadata": {},
   "source": [
    "# Likelihood based approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc55e91",
   "metadata": {},
   "source": [
    "In this tutorial, we implement the maximum likelihood estimation approach and compare with variogram\n",
    "fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bbe50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preamble \n",
    "\n",
    "import numpy as np\n",
    "import gstlearn as gl\n",
    "import gstlearn.plot as gp\n",
    "import scipy as sc \n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123134)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9bdde",
   "metadata": {},
   "source": [
    "## Zero mean stationary GRF model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4290d",
   "metadata": {},
   "source": [
    "We first define a zero mean GRF $Z$ model through its covariance function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7de389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the coordinates\n",
    "ndat = 200\n",
    "x=np.random.uniform(size=ndat)\n",
    "y=np.random.uniform(size=ndat)\n",
    "dbsim = gl.Db.create()\n",
    "dbsim[\"x\"]=x\n",
    "dbsim[\"y\"]=y\n",
    "dbsim.setLocators([\"x\",\"y\"],gl.ELoc.X)\n",
    "\n",
    "# Creation of the covariance model\n",
    "rangeval = 0.3\n",
    "model1 = gl.Model.createFromParam(gl.ECov.EXPONENTIAL,range = rangeval)\n",
    "\n",
    "#Simulation of a data set\n",
    "err=gl.simtub(None,dbsim,model=model1,nbtuba=1000)\n",
    "\n",
    "#Split train and test (proportion 50%)\n",
    "ind = np.arange(ndat)\n",
    "np.random.shuffle(ind)\n",
    "indtrain = ind[:int(ndat/2)]\n",
    "indtest  = ind[int(ndat/2):]\n",
    "dbtrain = gl.Db.createReduce(dbsim,ranks = indtrain)\n",
    "dbtest = gl.Db.createReduce(dbsim,ranks = indtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d364b32e",
   "metadata": {},
   "source": [
    "## Empirical variogram approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "varioParamOmni = gl.VarioParam.createOmniDirection(npas=9, dpas=0.07, toldis=0.1)\n",
    "vario = gl.Vario.computeFromDb(varioParamOmni,dbtrain)\n",
    "gp.plot(vario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitmod = gl.Model()\n",
    "err = fitmod.fit(vario)\n",
    "fitmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e872c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gp.varmod(vario, fitmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad9bb8",
   "metadata": {},
   "source": [
    "### Evaluation of the covariance matrix\n",
    "\n",
    "We use the method **evalCovMatrix** of the class **gl.Model**. The result is of type **gl.Matrix**. We use the method **gl.Matrix.toTL**  to transform it into a **np.array** (**toTL** helps you to transform an object of **gstlearn** into the Target Language, here python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "covmat = fitmod.evalCovMatrix(dbtrain).toTL()\n",
    "covmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dcb5e",
   "metadata": {},
   "source": [
    "Here we define the likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "C = np.random.uniform(size = (4,4))\n",
    "C = C.T@C\n",
    "np.linalg.slogdet(C)[1]\n",
    "\n",
    "F = np.ones(shape=(ndat,1))\n",
    "betavect = np.atleast_1d(0.3)\n",
    "F@betavect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36e6b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg2logLikelihood(db,model,sigma,theta,beta = 0.,F=None):\n",
    "    ndat = db.getSampleNumber()\n",
    "    if F is None:\n",
    "        F = np.ones(shape=(ndat,1)) #Vector of 1 for the mean parameter\n",
    "    \n",
    "    model.getCova(0).setRangeIsotropic(theta) #Fix range of the covariance model\n",
    "    model.getCova(0).setSill(sigma**2) #Sill\n",
    "    z = dbtrain.getColumnByLocator(gl.ELoc.Z) #Get variable Z\n",
    "    betavect = np.atleast_1d(beta) # make beta a vector (in case where a single value is given)\n",
    "    C = model.evalCovMatrix(dbtrain).toTL() #Covariance matrix\n",
    "\n",
    "    logdet = np.linalg.slogdet(C)[1] # log determinant\n",
    "    Zc = z-F@betavect #Centered bvector\n",
    "    Cm1Zc = np.linalg.solve(C,Zc)\n",
    "    quad = Zc.T@Cm1Zc #Quadratic term\n",
    "    return logdet + quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4fe146",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMLE = fitmod.clone()\n",
    "neg2logLikelihood(dbtrain,modelMLE,0.5,0.2,0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce710e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg2logLikelihoodForOptim(params,db,model,X=None):\n",
    "    sigma = params[0]\n",
    "    theta = params[1]\n",
    "    beta = params[2:]  \n",
    "    result = neg2logLikelihood(db,model,sigma,theta,beta,X)\n",
    "    print(\"sill \" +        str(np.round(sigma**2,2)) + \n",
    "          \" range \" +      str(np.round(theta,2)) +\n",
    "          \" mean \" +       str(np.round(beta,2)) + \n",
    "          \" likelihood \" + str(np.round(result,2)))\n",
    "    return result\n",
    "\n",
    "def fitMLE(params,db,model,X = None):\n",
    "    bds = ((0.00001,10),(0.00001,10)) + tuple((None, None) for _ in range(len(params)-2))\n",
    "    return sc.optimize.minimize(neg2logLikelihoodForOptim,params,\n",
    "                                args = (db,model,X),\n",
    "                                bounds= bds)\n",
    "                                \n",
    "    \n",
    "result = fitMLE(np.array([1,0.1,0.]),dbtrain,modelMLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "-fitmod.computeLogLikelihood(dbtrain) -  ndat/2 * np.log(2*np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14139e15",
   "metadata": {},
   "source": [
    "Estimated parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35944238",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbaf0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.plot(model1,label=\"True model\")\n",
    "gp.plot(modelMLE,label=\"Maximum Likelihood\")\n",
    "gp.plot(vario,label=\"Empirical\")\n",
    "gp.plot(fitmod,label=\"Automatic fitting\")\n",
    "plt.xlim([0,0.6])\n",
    "aa=plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99cb85",
   "metadata": {},
   "source": [
    "Comparison with the Simple kriging with the mean estimated by maximum likelihood and ordinary kriging with the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48d5e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMLE.setMean(result.x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.kriging(dbtrain,dbtest,modelMLE,gl.NeighUnique(),namconv=gl.NamingConvention(\"MLE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b67fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitmod.setDriftIRF(0)\n",
    "gl.kriging(dbtrain,dbtest,fitmod,gl.NeighUnique(),namconv=gl.NamingConvention(\"OK\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c47fbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "krigingVario = dbtest[\"MLE*estim\"]\n",
    "krigingMLE = dbtest[\"OK*estim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015103cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE with MLE \" + str(np.mean((krigingMLE-dbtest[\"Simu\"])**2)))\n",
    "print(\"MSE with vario \" + str(np.mean((krigingVario-dbtest[\"Simu\"])**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43744f8a",
   "metadata": {},
   "source": [
    "## First order non stationary GRF model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5ee5a",
   "metadata": {},
   "source": [
    "We now add a trend term $Z_2(x, y) = a + bx + cy + Z(x, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4181c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.array([1,2,3])\n",
    "\n",
    "#We duplicate the coordinates and affect them the role of a drift (locator F)\n",
    "dbsim[\"v1\"] = dbsim[\"x\"]\n",
    "dbsim[\"v2\"] = dbsim[\"y\"]\n",
    "dbsim.setLocators([\"v*\"],gl.ELoc.F)\n",
    "\n",
    "X = np.hstack([np.ones(shape=(ndat,1)),dbsim[\"v*\"]]) #We stack a column of ones\n",
    "\n",
    "#We add the total drift to the GRF\n",
    "dbsim[\"Simu\"] = X@beta + dbsim[\"Simu\"]\n",
    "\n",
    "#Split as previously\n",
    "dbtrain = gl.Db.createReduce(dbsim,ranks = indtrain)\n",
    "dbtest = gl.Db.createReduce(dbsim,ranks = indtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f906e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We specify to the model that there are two drift variables\n",
    "fitmod.setDriftIRF(nfex = 2)\n",
    "fitmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variogram of the residuals\n",
    "varioKED =gl.Vario.computeFromDb(varioParamOmni,dbtrain,model=fitmod)\n",
    "gp.plot(vario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d45418",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fitMLE(np.array([1,0.1,0.,0.,0.]),dbtrain,modelMLE,X[indtrain,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.kriging(dbtrain,dbtest,fitmod,gl.NeighUnique(),namconv=gl.NamingConvention(\"KED\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b13ff8",
   "metadata": {},
   "source": [
    "Kriging (residuals) by using the maximul likelihood estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6938c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of the residuals\n",
    "dbtrain[\"residual\"] =  dbtrain[\"Simu\"]-X[indtrain,:]@result.x[2:]\n",
    "dbtrain.setLocator(\"residual\",gl.ELoc.Z)\n",
    "modelMLE.setMean(0)\n",
    "gl.kriging(dbtrain,dbtest,modelMLE,gl.NeighUnique(),namconv=gl.NamingConvention(\"MLE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((dbtest[\"Simu\"]-dbtest[\"KED*estim\"])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "29dc47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtest[\"krigingMLE\"] = dbtest[\"MLE.residual.estim\"]+ X[indtest,:]@result.x[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((dbtest[\"Simu\"]-dbtest[\"krigingMLE\"])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b728416",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d8441c",
   "metadata": {},
   "source": [
    "1. Repeat the procedure for 100 simulations for both models and methods. Print a table containing the mean and\n",
    "standard deviation of the estimated parameter values and the MSEs.\n",
    "2. Implement the profile log-likelihood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
