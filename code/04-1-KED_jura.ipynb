{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kriging with external drift estimation on Jura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gstlearn as gl\n",
    "import gstlearn.plot as gp\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the data set and the prediction grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the data and the prediction grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "jura_all=pd.read_csv(\"jura/jura_pred.csv\")\n",
    "# Prediction grid\n",
    "grid = pd.read_csv(\"jura/jura_grid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the names of the Land Use and Rock in order to be consistent with their names on the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace landuse interger code by name\n",
    "landuse_codes=[1,2,3,4]\n",
    "landuse_names=[\"Forest\",\"Pasture\",\"Meadow\",\"Tillage\"]\n",
    "jura_all[\"Landuse\"]=jura_all[\"Landuse\"].replace(landuse_codes,landuse_names)\n",
    "\n",
    "## Replace rock type interger code by name\n",
    "rock_codes=[1,2,3,4,5]\n",
    "rock_names=[\"Argovian\",\"Kimmeridgian\",\"Sequanian\",\"Portlandian\",\"Quaternary\"]\n",
    "jura_all[\"Rock\"]=jura_all[\"Rock\"].replace(rock_codes,rock_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the predictor variables corresponding to Rock with one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# drop the first column for each feature\n",
    "enc = OneHotEncoder(handle_unknown='ignore',drop='first')\n",
    "enc.fit(jura_all[[\"Rock\"]])\n",
    "rock_indic_jura = pd.DataFrame(enc.transform(jura_all[[\"Rock\"]]).toarray(),columns = [\"Rock_K\",\"Rock_P\",\"Rock_Q\",\"Rock_S\"])\n",
    "jura_all = pd.concat([jura_all,rock_indic_jura],axis=1)\n",
    "rock_indic_grid = pd.DataFrame(enc.transform(grid[[\"Rock\"]]).toarray(),columns = [\"Rock_K\",\"Rock_P\",\"Rock_Q\",\"Rock_S\"])\n",
    "grid = pd.concat([grid,rock_indic_grid],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data set in two sets : the training set and the validation set.\n",
    "For the project and the Kaggle competition, you should use the full data set for \n",
    "the training.\n",
    "You will submit your prediction on Kaggle for a set of locations on which you will \n",
    "only know the locations and the factors of Land Use and Rock at these locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntot = jura_all.shape[0]\n",
    "ntrain = 200\n",
    "nval = ntot - ntrain\n",
    "\n",
    "indtrain = np.random.choice(ntot,ntrain,replace=False).astype(int)\n",
    "indval = np.setdiff1d(np.arange(ntot),indtrain)\n",
    "\n",
    "jura =jura_all.loc[indtrain,:]\n",
    "\n",
    "#val contains the values to predict. For the project, these values will be on Kaggle\n",
    "#(for other locations) and you won't know them\n",
    "#You will have the locations and covariables at the unknown locations by the following command :\n",
    "val_loc =jura_all.loc[indval,['Xloc','Yloc',\"Rock_K\",\"Rock_P\",\"Rock_Q\",\"Rock_S\"]]\n",
    "val=jura_all.loc[indval,['Co']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gstlearn objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a gstlearn database containing the data points, and assign the appropriate locators to the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Db\n",
    "db_jura=gl.Db_fromPanda(jura)\n",
    "\n",
    "## Set locators\n",
    "db_jura.setLocators(['Xloc','Yloc'],gl.ELoc.X) # -> Role = Coordinates\n",
    "db_jura.setLocators(['Co'],gl.ELoc.Z) # -> Role  = Variable of interest\n",
    "db_jura.setLocators([\"Rock*\"],gl.ELoc.F) # -> Role = Drift functions\n",
    "\n",
    "db_jura.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a gstlearn *Grid Database* containing the target grid for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load grid data into  point database\n",
    "db_grid_pts=gl.Db_fromPanda(grid)\n",
    "db_grid_pts.setLocators([\"Xloc\",\"Yloc\"],gl.ELoc.X)\n",
    "db_grid_pts.setLocators([\"Rock*\"],gl.ELoc.F)\n",
    "\n",
    "### Create empty grid database with right dimensions\n",
    "db_grid=gl.DbGrid.createCoveringDb(db_jura,dx=[0.05,0.05],margin=[0.2,0.2])\n",
    "\n",
    "### Migrate variables from point database to grid database\n",
    "err=gl.migrateMulti(db_grid_pts,db_grid,\n",
    "                    names=[\"Rock_K\",\"Rock_P\",\"Rock_Q\",\"Rock_S\"],\n",
    "                    namconv=gl.NamingConvention())\n",
    "\n",
    "### Add selection \n",
    "db_grid.addSelection(~np.isnan(db_grid[\"Rock_K\"]))## Create DbGrid that covers the Db containing the data\n",
    "db_grid.setLocators([\"Rock*\"],gl.ELoc.F)\n",
    "db_grid.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a Db containing the validation locations and the value of Cobalt concentrations at those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Db\n",
    "db_val=gl.Db_fromPanda(val_loc)\n",
    "\n",
    "## Set locators\n",
    "db_val.setLocators(['Xloc','Yloc'],gl.ELoc.X) # -> Role = Coordinates\n",
    "db_val.setLocators([\"Rock*\"],gl.ELoc.F) # -> Role = Drift functions\n",
    "\n",
    "## Add Co values\n",
    "db_val[\"Co\"]=val\n",
    "\n",
    "db_val.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variography of the residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model with a constant mean (*order = 0*) and the number of variables with a f locator the we want to work with (*nfex = 4*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDmodel = gl.Model()\n",
    "EDmodel.setDriftIRF(nfex = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the variogram of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create experimental variogram parametrization:\n",
    "## Setup parameters for a variogram with 30 lags separated by a distance 0.1 (meaning that we compute the variogram at lags h=0.1*i for i=0,...,30),\n",
    "## and consider a tolerance Ï„=50% on the distance\n",
    "varioParamOmni = gl.VarioParam.createOmniDirection(npas=30, dpas=0.1, toldis=0.5)\n",
    "\n",
    "## Create experimental variogram object with specified parameters\n",
    "varioRaw = gl.Vario(varioParamOmni) #Raw variable for comparison purpose\n",
    "varioKED = gl.Vario(varioParamOmni)\n",
    "\n",
    "## Compute experimental variogram\n",
    "err = varioRaw.compute(db_jura)\n",
    "err = varioKED.compute(db_jura,model=EDmodel) #We pass the model to indicate\n",
    "                                              #that we work on residuals which will\n",
    "                                              #be computed by the function.\n",
    "\n",
    "## Plot\n",
    "ax = gp.varmod(varioRaw,showPairs=False,label = \"Raw\")\n",
    "ax = gp.varmod(varioKED,showPairs=False,color = \"r\",label = \"Residual\")\n",
    "ax = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Model objects\n",
    "fitmodRaw = gl.Model()\n",
    "fitmodKED = gl.Model()\n",
    "\n",
    "## set the drift within the model\n",
    "fitmodRaw.setDriftIRF(order = 0)\n",
    "fitmodKED.setDriftIRF(order = 0, nfex = 4)\n",
    "\n",
    "## Fit model on experimental variogram\n",
    "err = fitmodRaw.fit(varioRaw, types = [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL])\n",
    "err = fitmodKED.fit(varioKED, types = [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL])\n",
    "\n",
    "## Plot\n",
    "gp.varmod(varioKED, fitmodKED)\n",
    "gp.varmod(varioRaw, fitmodRaw,color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriging with external Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *kriging* function is called to perform the kriging with external drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the neighborhood\n",
    "uniqueNeigh = gl.NeighUnique.create()\n",
    "\n",
    "## Remove variables starting with a given prefix (-> Results from previous runs)\n",
    "db_grid.deleteColumns([\"KED*\"])\n",
    "db_grid.deleteColumns([\"OK*\"])\n",
    "\n",
    "## Compute kriging\n",
    "err = gl.kriging(dbin=db_jura, dbout=db_grid, model=fitmodKED, \n",
    "              neigh=uniqueNeigh,\n",
    "              flag_est=True, flag_std=True, flag_varz=False, ## To compute the predictor and its standard-deviation, but not its variance\n",
    "              namconv=gl.NamingConvention(\"KED\") ## Prefix that will be used to identify the results in the output database\n",
    "              )\n",
    "\n",
    "## Compute ordinary kriging for comparison\n",
    "err = gl.kriging(dbin=db_jura, dbout=db_grid, model=fitmodRaw, \n",
    "              neigh=uniqueNeigh,\n",
    "              flag_est=True, flag_std=True, flag_varz=False, ## To compute the predictor and its standard-deviation, but not its variance\n",
    "              namconv=gl.NamingConvention(\"OK\") ## Prefix that will be used to identify the results in the output database\n",
    "              )\n",
    "## Display database\n",
    "db_grid.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask for the regression coefficients using *regression*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regResults = gl.regression(db_jura, nameResp=\"Co\",  model=fitmodKED, mode=2)\n",
    "regResults.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot prediction\n",
    "fig, ax = gp.initGeographic()\n",
    "ax.raster(db_grid, name=\"KED*estim\",flagLegend=True)\n",
    "ax.symbol(db_jura, c='black')\n",
    "ax.decoration(title=\"Kriging with external Drift prediction\")\n",
    "plt.show()\n",
    "\n",
    "## Plot kriging standard-deviation\n",
    "fig, ax = gp.initGeographic()\n",
    "ax.raster(db_grid, name=\"KED*stdev\",flagLegend=True)\n",
    "ax.symbol(db_jura, c='black')\n",
    "ax.decoration(title=\"Kriging with external Drift standard-deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the KED prediction at the validation locations and the resulting RMSE can then be done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove variables starting with a given prefix (-> Results from previous runs)\n",
    "db_val.deleteColumns([\"OK*\"])\n",
    "db_val.deleteColumns([\"KED*\"])\n",
    "\n",
    "## Compute kriging\n",
    "err = gl.kriging(dbin=db_jura, dbout=db_val, model=fitmodKED, \n",
    "              neigh=uniqueNeigh,\n",
    "              flag_est=True, flag_std=True, flag_varz=False, ## To compute the predictor and its standard-deviation, but not its variance\n",
    "              namconv=gl.NamingConvention(\"KED\") ## Prefix that will be used to identify the results in the output database\n",
    "              )\n",
    "\n",
    "err = gl.kriging(dbin=db_jura, dbout=db_val, model=fitmodRaw, \n",
    "              neigh=uniqueNeigh,\n",
    "              flag_est=True, flag_std=True, flag_varz=False, ## To compute the predictor and its standard-deviation, but not its variance\n",
    "              namconv=gl.NamingConvention(\"OK\") ## Prefix that will be used to identify the results in the output database\n",
    "              )\n",
    "## Compute RMSE\n",
    "rmse_KED=np.mean((db_val[\"Co\"]-db_val[\"KED*estim\"])**2)**0.5\n",
    "rmse_OK=np.mean((db_val[\"Co\"]-db_val[\"OK*estim\"])**2)**0.5\n",
    "\n",
    "print(\"Ordinary Kriging RMSE\",rmse_OK)\n",
    "print(\"KED RMSE\",rmse_KED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. Improve the model by adding other explanatory variables (e.g. Landuse or the interactions Rock*Landuse).\n",
    "2. Estimate the model parameters by maximum Likelihood.\n",
    "3. Define and adjust a multivariate model with drift. Compute the associated predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
